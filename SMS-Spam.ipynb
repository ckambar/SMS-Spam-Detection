{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c258577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tkinter import *\n",
    "\n",
    "# Initialise a count vectorizer and split the dataset into training and testing data.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "class SpamClassifier:\n",
    "    def __init__(self):\n",
    "        self.dataFrame_Messages, self.dataFrame_Label=self.Data_Cleanup()\n",
    "        self.SMS_Classifier, self.count_Vectorizer=self.Create_Classifier()\n",
    "        \n",
    "    def Data_Cleanup(self):\n",
    "        data=pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "        data=data.drop([\"Unnamed: 0\"], 1)\n",
    "        data=data.rename(columns={\"v1\":\"label\", \"v2\":\"message\"})\n",
    "        \n",
    "        # Convert spam=1 and ham=0 for ease of working with the ML model\n",
    "        df=data\n",
    "        df.loc[df['label']=='spam', 'label']=1\n",
    "        df.loc[df['label']=='ham', 'label']=0\n",
    "        \n",
    "        # Split messages and label so as to divide them into test and training data, \n",
    "        df_x = df['message']\n",
    "        df_y = df['label']\n",
    "        \n",
    "        #print(df.head())\n",
    "        #print(self.dataset.head())\n",
    "        \n",
    "        return df_x, df_y\n",
    "    \n",
    "    def Create_Classifier(self):\n",
    "        \n",
    "        def Classifier_Test():\n",
    "            \n",
    "            # Transform the test data using Count Vectorizer and test for accuracy\n",
    "            testing_Data=cv.transform(messages_For_Test)\n",
    "            predicted_Output=spam_Classifier.predict(testing_Data)\n",
    "            expected_Output=np.array(labels_For_Test)\n",
    "            \n",
    "            # Convert the test data into the similar format as of predicted_Output, so that the confusion matrix can be generated.\n",
    "            expected_Output_List=[]\n",
    "            for output in expected_Output:\n",
    "                expected_Output_List.append(output)\n",
    "            \n",
    "            precisionScore = precision_score(expected_Output_List, predicted_Output)\n",
    "            recallScore = recall_score(expected_Output_List, predicted_Output)\n",
    "            f1Score = f1_score(expected_Output_List, predicted_Output)\n",
    "            accuracyScore = accuracy_score(expected_Output_List, predicted_Output)\n",
    "            confusionMatrix = confusion_matrix(expected_Output_List, predicted_Output)\n",
    "            \n",
    "            result={\"precisionScore\":precisionScore, \"recallScore\":recallScore, \"f1Score\":f1Score, \"accuracyScore\":accuracyScore, \"confusionMatrix\":confusionMatrix}\n",
    "            \n",
    "            return result\n",
    "            \n",
    "            \n",
    "        cv=CountVectorizer()\n",
    "        messages_For_Train, messages_For_Test, labels_For_Train, labels_For_Test = train_test_split(self.dataFrame_Messages, self.dataFrame_Label, test_size=0.5, random_state=4)\n",
    "        \n",
    "        # Transform the training data using the count vectorizer, this creates a frequency array of words for each message \n",
    "        training_Data = cv.fit_transform(messages_For_Train)\n",
    "        \n",
    "        ## The features/words extracted by the count vectorizer from the training dataset.\n",
    "        ## Each  message will be checked for these words.\n",
    "        #cv.get_feature_names()\n",
    "        \n",
    "        ## trainig_Data_Array represents for each message in the dataset, how many times a feature/word has been repeated\n",
    "        training_Data_Array = training_Data.toarray()\n",
    "        ## The number of messages in training set and how many have been checked by Count Vectorizer\n",
    "        #len(arr)\n",
    "        \n",
    "        spam_Classifier = MultinomialNB()\n",
    "        \n",
    "        # Conversion of training data of 0's and 1's into integers as they are strings by default\n",
    "        labels_For_Train = labels_For_Train.astype('int')\n",
    "        \n",
    "        spam_Classifier.fit(training_Data,  labels_For_Train)\n",
    "        \n",
    "        test_Results=Classifier_Test()\n",
    "        \n",
    "        #print(test_Results)\n",
    "        \n",
    "        return spam_Classifier, cv\n",
    "    \n",
    "\n",
    "class App:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.input_List=[]\n",
    "        self.Spam_Classifier=SpamClassifier()\n",
    "    \n",
    "    def Start_App(self):\n",
    "        \n",
    "        def Submit():\n",
    "            input_Text=user_Input.get()\n",
    "            if(input_Text!=\"\"):\n",
    "                self.input_List.append(input_Text)\n",
    "                userInputEntry.delete(0, END)\n",
    "                prediction_Text=self.Get_Prediction()\n",
    "                outputLabel.config(text=prediction_Text)\n",
    "            else:\n",
    "                outputLabel.config(text=\"Please enter a message.\")\n",
    "            \n",
    "            prediction_Text=\"\"\n",
    "                \n",
    "\n",
    "        def Exit():\n",
    "            mainWindow.destroy()\n",
    "\n",
    "        mainWindow=Tk()\n",
    "        mainWindow.title(\"SMS Spam Classifier\")\n",
    "        mainWindow.geometry(\"400x400\")\n",
    "\n",
    "        welcomeLabel=Label(master=mainWindow, text=\"Welcome To SMS CLASSIFIER\")\n",
    "        welcomeLabel.grid(row=0, column=0, columnspan=5, padx=100, pady=40)\n",
    "\n",
    "        userInputLabelFrame=LabelFrame(master=mainWindow, text=\"Enter SMS to be classified\")\n",
    "        userInputLabelFrame.grid(row=1, column=0, rowspan=3, columnspan=5, padx=30)\n",
    "        \n",
    "        user_Input=StringVar()\n",
    "        userInputEntry=Entry(master=userInputLabelFrame, textvariable=user_Input)\n",
    "        userInputEntry.grid(row=4, column=0, columnspan=5, padx=100, pady=20)\n",
    "\n",
    "        outputLabel=Label(master=mainWindow, text=\"\")\n",
    "        outputLabel.grid(row=5, column=0, columnspan=5, padx=100, pady=10)\n",
    "\n",
    "        submitButton=Button(mainWindow, text=\"Submit\", command=Submit)\n",
    "        submitButton.grid(row=6, column=0, columnspan=3, padx=10, pady=20)\n",
    "\n",
    "        exitButton=Button(mainWindow, text=\"     Exit     \", command=Exit)\n",
    "        exitButton.grid(row=6, column=2, columnspan=3, padx=10, pady=20)\n",
    "\n",
    "        mainWindow.mainloop()\n",
    "    \n",
    "\n",
    "        \n",
    "    def Get_Prediction(self):\n",
    "        output_Text=None\n",
    "        latest_Index=len(self.input_List)-1\n",
    "        test_Data = self.Spam_Classifier.count_Vectorizer.transform(self.input_List)\n",
    "        prediction = self.Spam_Classifier.SMS_Classifier.predict(test_Data)\n",
    "        prediction = prediction.tolist()\n",
    "        print(prediction)\n",
    "        if prediction[latest_Index]==1:\n",
    "            output_Text=\"SMS is SPAM: Be cautious......\"\n",
    "        else:\n",
    "            output_Text=\"SMS is NOT SPAM: You are safe.....\"\n",
    "        return output_Text\n",
    "                \n",
    "    def Write_To_CSV(self):\n",
    "        user_Input_Dictionary={\n",
    "            \"label\":self.classification_Of_Input_List,\n",
    "            \"message\":self.input_List\n",
    "        }\n",
    "        \n",
    "        user_Input_Data_Frame=pd.DataFrame(user_Input_Dictionary)\n",
    "        data_Frame_To_Write=user_Input_Data_Frame.append(self.Spam_Classifier.data)\n",
    "        data_Frame_To_Write.loc[data_Frame_To_Write['label']==1, 'label']=\"spam\"\n",
    "        data_Frame_To_Write.loc[data_Frame_To_Write['label']==0, 'label']=\"ham\"\n",
    "        #print(data_Frame_To_Write)\n",
    "        data_Frame_To_Write.to_csv(\"spam-appended.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5b2bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chint\\AppData\\Local\\Temp/ipykernel_12772/1935536903.py:21: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data=data.drop([\"Unnamed: 0\"], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 0]\n",
      "[1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# \"Dear Customer your pyatm wallet Has been booked and hold Your amount please complete your kyc contact customer care 6200992462\"\n",
    "# \"Junglee Rummy win 1000RS\"\n",
    "# \"Hey John, Hope you are doing fine, I am in Chicago for a week, let us catch up sometime. Have a great day !\"\n",
    "classifier_App = App()   \n",
    "classifier_App.Start_App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e35df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0e409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645adec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200e3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd0ef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065811d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb4473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f71b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f6388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5fc2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678b415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3723b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f52c5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1586e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08fc65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f64dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f579e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44eb8aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdcee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1f7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40a18d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
